{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87edd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro avg (Média Macro) = Calcula a média aritmética simples das métricas (precisão, recall, F1-Score) entre todas as classes, dando o mesmo peso a cada classe, independentemente do número de amostras.\n",
    "# Quando todas as classes são igualmente importantes, mesmo que tenham tamanhos diferentes.\n",
    "# Útil para detectar se o modelo tem viés contra classes minoritárias.\n",
    "\n",
    "# # Weighted Average(Média Ponderada) = Calcula a média das métricas ponderando cada classe pelo seu suporte (número de amostras). Classes com mais exemplos têm maior influência no resultado.\n",
    "# Quando o desbalanceamento das classes reflete a importância relativa no mundo real.\n",
    "# Útil para cenários onde classes maiores são mais críticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo possui media macro mais consistente pelo graf 3, com menor diferenca entre teste e validacao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9602466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0480b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# functions \n",
    "\n",
    "# Função para processar classification reports\n",
    "def process_report(report, model_name, dataset_type):\n",
    "    metrics = []\n",
    "    # Processar métricas por classe\n",
    "    for class_name in CLASSES:\n",
    "        class_metrics = report[class_name]\n",
    "        metrics.append({\n",
    "            'Modelo': model_name,\n",
    "            'Conjunto': dataset_type,\n",
    "            'Classe': class_name,\n",
    "            'Precisão': class_metrics['precision'],\n",
    "            'Recall': class_metrics['recall'],\n",
    "            'F1-Score': class_metrics['f1-score'],\n",
    "            'Suporte': class_metrics['support']\n",
    "        })\n",
    "    \n",
    "    # Processar métricas agregadas\n",
    "    metrics.append({\n",
    "        'Modelo': model_name,\n",
    "        'Conjunto': dataset_type,\n",
    "        'Classe': 'Macro Avg',\n",
    "        'Precisão': report['macro avg']['precision'],\n",
    "        'Recall': report['macro avg']['recall'],\n",
    "        'F1-Score': report['macro avg']['f1-score'],\n",
    "        'Suporte': report['macro avg']['support']\n",
    "    })\n",
    "    \n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# 1. Métricas por Classe (Atualizada)\n",
    "def plot_metricas_por_classe(df):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "    for i, metric in enumerate(['Precisão', 'Recall', 'F1-Score']):\n",
    "        ax = axes[i]\n",
    "        sns.barplot(data=df[df['Classe'] != 'Macro Avg'],\n",
    "                    x='Classe', y=metric, hue='Modelo',\n",
    "                    ci=None, ax=ax)\n",
    "        ax.set_title(f'{metric} por Classe e Modelo')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f\"{p.get_height():.2f}\",\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='center',\n",
    "                        xytext=(0, 10),\n",
    "                        textcoords='offset points')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/metricas_por_classe.jpg', dpi=300, bbox_inches='tight')  # Nova linha\n",
    "    plt.close()  # Fechar a figura após salvar\n",
    "\n",
    "# 2. Consistência entre Validação e Teste (Atualizada)\n",
    "def plot_consistencia(df):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "    for i, metric in enumerate(['Precisão', 'Recall', 'F1-Score']):\n",
    "        ax = axes[i]\n",
    "        sns.lineplot(data=df, x='Conjunto', y=metric, hue='Modelo',\n",
    "                     style='Classe', markers=True, dashes=False, ax=ax)\n",
    "        ax.set_title(f'Consistência de {metric} entre Conjuntos')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/consistencia_metricas.jpg', dpi=300, bbox_inches='tight')  # Nova linha\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 3. Métricas Gerais Agrupadas (Atualizada)\n",
    "def plot_metricas_gerais(df):\n",
    "    grouped = df.groupby(['Modelo', 'Conjunto']).agg({\n",
    "        'Precisão': 'mean',\n",
    "        'Recall': 'mean',\n",
    "        'F1-Score': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "    for i, metric in enumerate(['Precisão', 'Recall', 'F1-Score']):\n",
    "        ax = axes[i]\n",
    "        sns.barplot(data=grouped, x='Modelo', y=metric, hue='Conjunto', ax=ax)\n",
    "        ax.set_title(f'Média Geral de {metric}')\n",
    "        ax.set_ylim(0, 1)\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f\"{p.get_height():.2f}\",\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='center',\n",
    "                        xytext=(0, 10),\n",
    "                        textcoords='offset points')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/metricas_gerais.jpg', dpi=300, bbox_inches='tight')  # Nova linha\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_best_model(X_train, X_val, y_train, y_val, target_names):\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    classifiers = {\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "        'SVC': SVC(probability=True),\n",
    "        'GradientBoosting': GradientBoostingClassifier()\n",
    "    }\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        try:\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_val)\n",
    "            f1 = f1_score(y_val, y_pred, average='macro')\n",
    "            results.append({'Modelo': name, 'Macro Avg F1': f1})\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = clf\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro em {name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Retreinar o melhor modelo com todos os dados\n",
    "    if best_model is not None:\n",
    "        best_model.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "    return best_model, pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfbc54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro em RandomForest: Found input variables with inconsistent numbers of samples: [355, 342]\n",
      "Erro em LogisticRegression: Found input variables with inconsistent numbers of samples: [355, 342]\n",
      "Erro em SVC: Found input variables with inconsistent numbers of samples: [355, 342]\n",
      "Erro em GradientBoosting: Found input variables with inconsistent numbers of samples: [355, 342]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Encontrar melhor classificador para MediaPipe\u001b[39;00m\n\u001b[32m     55\u001b[39m best_clf_mp, mp_metrics = get_best_model(X_train_mp, X_val_mp, y_train_mp, y_val_mp, CLASSES)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mbest_clf_mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m(X_train_mp, y_train_mp)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Avaliar\u001b[39;00m\n\u001b[32m     59\u001b[39m y_pred_mp_val = best_clf_mp.predict(X_val_mp)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "CLASSES = ['sitting', 'standing', 'walking']\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "# Coletar dados para comparação\n",
    "all_metrics = []\n",
    "\n",
    "# =================================================================\n",
    "# Processar resultados do YOLO\n",
    "# =================================================================\n",
    "## for YOLO model\n",
    "# Carregar dados\n",
    "X_train_yolo = np.load(\"../results/model_1_features/yolo_features_train_norm1.npy\")\n",
    "y_train_yolo = np.load(\"../results/model_1_features/yolo_labels_train_norm1.npy\")\n",
    "X_val_yolo = np.load(\"../results/model_1_features/yolo_features_val_norm1.npy\")\n",
    "y_val_yolo = np.load(\"../results/model_1_features/yolo_labels_val_norm1.npy\")\n",
    "X_test_yolo = np.load(\"../results/model_1_features/yolo_features_test_norm1.npy\")\n",
    "y_test_yolo = np.load(\"../results/model_1_features/yolo_labels_test_norm1.npy\")\n",
    "\n",
    "# Encontrar melhor classificador para YOLO\n",
    "best_clf_yolo, yolo_metrics = get_best_model(X_train_yolo, X_val_yolo, y_train_yolo, y_val_yolo, CLASSES)\n",
    "best_clf_yolo.fit(X_train_yolo, y_train_yolo)\n",
    "\n",
    "# Avaliar\n",
    "y_pred_yolo_val = best_clf_yolo.predict(X_val_yolo)\n",
    "y_pred_yolo_test = best_clf_yolo.predict(X_test_yolo)\n",
    "\n",
    "# Salvar melhor modelo YOLO\n",
    "joblib.dump(best_clf_yolo, \"../models/pose_classifier_yolo_best.pkl\")\n",
    "\n",
    "# Processar relatórios\n",
    "yolo_val_report = classification_report(y_val_yolo, y_pred_yolo_val, target_names=CLASSES, output_dict=True)\n",
    "yolo_test_report = classification_report(y_test_yolo, y_pred_yolo_test, target_names=CLASSES, output_dict=True)\n",
    "\n",
    "# Processar relatórios e adicionar às métricas\n",
    "all_metrics += process_report(yolo_val_report, 'YOLO', 'Validação')\n",
    "all_metrics += process_report(yolo_test_report, 'YOLO', 'Teste')\n",
    "\n",
    "# =================================================================\n",
    "# Processar resultados do MediaPipe\n",
    "# =================================================================\n",
    "\n",
    "\n",
    "## for MediaPipe model\n",
    "# Carregar dados\n",
    "X_train_mp = np.load(\"../results/model_2_mediapipe_features/mediapipe_features_train_norm1.npy\")\n",
    "y_train_mp = np.load(\"../results/model_2_mediapipe_features/mediapipe_labels_train_norm1.npy\")\n",
    "X_val_mp = np.load(\"../results/model_2_mediapipe_features/mediapipe_features_val_norm1.npy\")\n",
    "y_val_mp = np.load(\"../results/model_2_mediapipe_features/mediapipe_labels_val_norm1.npy\")\n",
    "X_test_mp = np.load(\"../results/model_2_mediapipe_features/mediapipe_features_test_norm1.npy\")\n",
    "y_test_mp= np.load(\"../results/model_2_mediapipe_features/mediapipe_labels_test_norm1.npy\")\n",
    "\n",
    "# Encontrar melhor classificador para MediaPipe\n",
    "best_clf_mp, mp_metrics = get_best_model(X_train_mp, X_val_mp, y_train_mp, y_val_mp, CLASSES)\n",
    "best_clf_mp.fit(X_train_mp, y_train_mp)\n",
    "\n",
    "# Avaliar\n",
    "y_pred_mp_val = best_clf_mp.predict(X_val_mp)\n",
    "y_pred_mp_test = best_clf_mp.predict(X_test_mp)\n",
    "\n",
    "# Salvar melhor modelo MediaPipe\n",
    "joblib.dump(best_clf_mp, \"../models/pose_classifier_mediapipe_best.pkl\")\n",
    "\n",
    "# Processar relatórios\n",
    "mediapipe_val_report = classification_report(y_val_mp, y_pred_mp_val, target_names=CLASSES, output_dict=True)\n",
    "mediapipe_test_report = classification_report(y_test_mp, y_pred_mp_test, target_names=CLASSES, output_dict=True)\n",
    "\n",
    "# Processar relatórios e adicionar às métricas\n",
    "all_metrics += process_report(mediapipe_val_report, 'MediaPipe', 'Validação')\n",
    "all_metrics += process_report(mediapipe_test_report, 'MediaPipe', 'Teste')\n",
    "# Criar DataFrame\n",
    "df_comparacao = pd.DataFrame(all_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab87c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Modelos YOLO:\n",
      "               Modelo  Macro Avg F1\n",
      "3    GradientBoosting          0.83\n",
      "0        RandomForest          0.81\n",
      "1  LogisticRegression          0.65\n",
      "2                 SVC          0.56\n",
      "\n",
      "Top 5 Modelos MediaPipe:\n",
      "               Modelo  Macro Avg F1\n",
      "3    GradientBoosting          0.82\n",
      "1  LogisticRegression          0.74\n",
      "0        RandomForest          0.70\n",
      "2                 SVC          0.59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Exibir métricas dos modelos testados\n",
    "print(\"Top 5 Modelos YOLO:\")\n",
    "print(yolo_metrics.sort_values('Macro Avg F1', ascending=False).head(5))\n",
    "\n",
    "print(\"\\nTop 5 Modelos MediaPipe:\")\n",
    "print(mp_metrics.sort_values('Macro Avg F1', ascending=False).head(5))\n",
    "\n",
    "# plot_metricas_por_classe(df_comparacao)\n",
    "# plot_consistencia(df_comparacao)\n",
    "# plot_metricas_gerais(df_comparacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646d5e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Conjunto</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Suporte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Validação</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Validação</td>\n",
       "      <td>standing</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Validação</td>\n",
       "      <td>walking</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Validação</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Teste</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Teste</td>\n",
       "      <td>standing</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Teste</td>\n",
       "      <td>walking</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>Teste</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Validação</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Validação</td>\n",
       "      <td>standing</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Validação</td>\n",
       "      <td>walking</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.86</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Validação</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>53.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Teste</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Teste</td>\n",
       "      <td>standing</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Teste</td>\n",
       "      <td>walking</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MediaPipe</td>\n",
       "      <td>Teste</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelo   Conjunto     Classe  Precisão  Recall  F1-Score  Suporte\n",
       "0        YOLO  Validação    sitting      0.88    0.95      0.91    22.00\n",
       "1        YOLO  Validação   standing      0.80    0.91      0.85    22.00\n",
       "2        YOLO  Validação    walking      1.00    0.58      0.74    12.00\n",
       "3        YOLO  Validação  Macro Avg      0.89    0.82      0.83    56.00\n",
       "4        YOLO      Teste    sitting      0.89    0.73      0.80    11.00\n",
       "5        YOLO      Teste   standing      0.57    0.73      0.64    11.00\n",
       "6        YOLO      Teste    walking      0.67    0.57      0.62     7.00\n",
       "7        YOLO      Teste  Macro Avg      0.71    0.68      0.69    29.00\n",
       "8   MediaPipe  Validação    sitting      0.80    0.91      0.85    22.00\n",
       "9   MediaPipe  Validação   standing      0.79    0.79      0.79    19.00\n",
       "10  MediaPipe  Validação    walking      1.00    0.75      0.86    12.00\n",
       "11  MediaPipe  Validação  Macro Avg      0.86    0.82      0.83    53.00\n",
       "12  MediaPipe      Teste    sitting      0.75    0.82      0.78    11.00\n",
       "13  MediaPipe      Teste   standing      0.67    0.40      0.50    10.00\n",
       "14  MediaPipe      Teste    walking      0.60    0.86      0.71     7.00\n",
       "15  MediaPipe      Teste  Macro Avg      0.67    0.69      0.66    28.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparacao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
